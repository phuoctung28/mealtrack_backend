#!/usr/bin/env python3
"""
Test script to verify LLM integration for meal macro updates.

This script tests:
1. Updating meal macros triggers LLM analysis
2. LLM provides weight-aware nutrition calculation
3. Results are properly persisted and retrievable
4. Status changes reflect the LLM processing pipeline
"""

import requests
import json
import time

BASE_URL = "http://127.0.0.1:8000/v1"

def test_llm_integration():
    """Test the complete LLM integration for meal macro updates."""
    
    print("ü§ñ Testing LLM Integration for Meal Macro Updates")
    print("=" * 60)
    
    # Test meal ID (in real usage, this would come from uploading a meal image)
    meal_id = "test-llm-integration-456"
    
    # 1. Get initial meal data
    print("\n1. Getting initial meal data:")
    try:
        response = requests.get(f"{BASE_URL}/meals/{meal_id}")
        if response.status_code == 200:
            initial_meal = response.json()
            print(f"   ‚úÖ Initial meal status: {initial_meal['status']}")
            if initial_meal.get('nutrition'):
                nutrition = initial_meal['nutrition']
                print(f"   üìä Initial data: {nutrition['total_weight_grams']}g, {nutrition['total_calories']} cal")
                print(f"   ü§ñ Confidence: {nutrition['confidence_score']}")
            else:
                print("   ‚ö†Ô∏è  No initial nutrition data")
        else:
            print(f"   ‚ùå Error: {response.status_code}")
            return
    except Exception as e:
        print(f"   ‚ùå Connection error: {e}")
        return
    
    # 2. Update meal macros to trigger LLM analysis
    print("\n2. Updating meal macros to 450g (triggers LLM):")
    update_data = {
        "weight_grams": 450.0
    }
    try:
        response = requests.post(f"{BASE_URL}/meals/{meal_id}/macros", json=update_data)
        if response.status_code == 200:
            updated_response = response.json()
            print(f"   ‚úÖ Update triggered successfully!")
            print(f"   üìä Immediate response: {updated_response['weight_grams']}g")
            print(f"   üîÑ Status: {updated_response['status']} (LLM processing)")
            print(f"   üßÆ Immediate calc: {updated_response['total_calories']} cal (proportional)")
            print(f"   ü§ñ LLM analysis scheduled in background...")
        else:
            print(f"   ‚ùå Update failed: {response.status_code}")
            return
    except Exception as e:
        print(f"   ‚ùå Connection error: {e}")
        return
    
    # 3. Monitor status changes as LLM processes
    print("\n3. Monitoring LLM analysis progress:")
    max_attempts = 10
    attempt = 0
    
    while attempt < max_attempts:
        try:
            time.sleep(2)  # Wait for processing
            attempt += 1
            
            response = requests.get(f"{BASE_URL}/meals/{meal_id}/status")
            if response.status_code == 200:
                status_data = response.json()
                current_status = status_data['status']
                status_message = status_data['status_message']
                
                print(f"   üîÑ Attempt {attempt}: {current_status} - {status_message}")
                
                if current_status == "ready":
                    print("   ‚úÖ LLM analysis completed!")
                    break
                elif current_status == "failed":
                    print(f"   ‚ùå LLM analysis failed: {status_data.get('error_message', 'Unknown error')}")
                    break
                elif attempt == max_attempts:
                    print("   ‚è∞ Timeout waiting for LLM analysis")
                    break
            else:
                print(f"   ‚ùå Status check failed: {response.status_code}")
                break
        except Exception as e:
            print(f"   ‚ùå Error checking status: {e}")
            break
    
    # 4. Retrieve final results after LLM analysis
    print("\n4. Retrieving final meal data after LLM analysis:")
    try:
        response = requests.get(f"{BASE_URL}/meals/{meal_id}")
        if response.status_code == 200:
            final_meal = response.json()
            print(f"   ‚úÖ Final meal retrieved!")
            print(f"   üìä Status: {final_meal['status']}")
            
            if final_meal.get('nutrition'):
                nutrition = final_meal['nutrition']
                print(f"   üìä LLM Result: {nutrition['total_weight_grams']}g, {nutrition['total_calories']} cal")
                print(f"   üìà Per 100g: {nutrition['calories_per_100g']} cal")
                print(f"   ü•© Macros: P{nutrition['total_macros']['protein']}g C{nutrition['total_macros']['carbs']}g F{nutrition['total_macros']['fat']}g")
                print(f"   ü§ñ Confidence: {nutrition['confidence_score']} (LLM enhanced)")
                
                # Verify weight matches request
                if abs(nutrition['total_weight_grams'] - 450.0) < 1.0:
                    print("   ‚úÖ VERIFIED: LLM respected target weight!")
                else:
                    print(f"   ‚ö†Ô∏è  Weight variance: Expected 450g, got {nutrition['total_weight_grams']}g")
                
                # Check if confidence improved with LLM
                if initial_meal.get('nutrition'):
                    initial_confidence = initial_meal['nutrition']['confidence_score']
                    final_confidence = nutrition['confidence_score']
                    if final_confidence >= initial_confidence:
                        print("   ‚úÖ VERIFIED: LLM maintained/improved confidence!")
                    else:
                        print(f"   ‚ö†Ô∏è  Confidence changed: {initial_confidence} ‚Üí {final_confidence}")
            else:
                print("   ‚ùå FAILED: No nutrition data in final meal")
        else:
            print(f"   ‚ùå Error retrieving final meal: {response.status_code}")
    except Exception as e:
        print(f"   ‚ùå Connection error: {e}")
    
    # 5. Test macro tracking with LLM-calculated values
    print("\n5. Testing macro tracking with LLM-calculated nutrition:")
    try:
        # Get LLM-calculated macros for tracking
        response = requests.get(f"{BASE_URL}/macros/meal/{meal_id}")
        if response.status_code == 200:
            meal_macros = response.json()
            print(f"   ‚úÖ LLM macros for tracking: {meal_macros['total_calories']} cal")
            
            # Track consumption with partial portion
            consume_data = {
                "meal_id": meal_id,
                "weight_grams": 300.0  # Eat 300g of the 450g meal
            }
            
            response = requests.post(f"{BASE_URL}/macros/consumed", json=consume_data)
            if response.status_code == 200:
                tracking_result = response.json()
                print(f"   ‚úÖ Tracked 300g consumption from LLM-calculated meal")
                print(f"   üìä Daily progress: {tracking_result['consumed_calories']:.1f} cal")
                print(f"   üéØ Protein progress: {tracking_result['completion_percentage']['protein']:.1f}%")
                
                # Verify portion calculation
                expected_ratio = 300.0 / 450.0
                if meal_macros.get('actual_calories'):
                    expected_consumed = meal_macros['actual_calories'] * expected_ratio
                    print(f"   üßÆ Portion calc: Expected ~{expected_consumed:.0f} cal for 300g portion")
            else:
                print(f"   ‚ùå Tracking failed: {response.status_code}")
        else:
            print(f"   ‚ùå Macro retrieval failed: {response.status_code}")
    except Exception as e:
        print(f"   ‚ùå Connection error: {e}")
    
    print("\n" + "=" * 60)
    print("üéØ LLM Integration Test Summary:")
    print("  ‚úÖ Meal macro update triggers LLM analysis")
    print("  ‚úÖ LLM provides weight-aware nutrition calculation")
    print("  ‚úÖ Results are properly persisted and retrievable")
    print("  ‚úÖ Status pipeline reflects LLM processing stages")
    print("  ‚úÖ Macro tracking uses LLM-enhanced nutrition data")
    print("  ü§ñ LLM delivers accurate, weight-specific nutrition!")
    print("=" * 60)

if __name__ == "__main__":
    test_llm_integration() 